<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>绿萝间 (Python)</title><link>http://muxuezi.github.io/</link><description></description><atom:link href="http://muxuezi.github.io/categories/python.xml" type="application/rss+xml" rel="self"></atom:link><language>en</language><lastBuildDate>Thu, 09 Jul 2015 07:22:55 GMT</lastBuildDate><generator>http://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>0-perface</title><link>http://muxuezi.github.io/posts/0-perface.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="前言"&gt;前言&lt;a class="anchor-link" href="http://muxuezi.github.io/posts/0-perface.html#%E5%89%8D%E8%A8%80"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;这几年机器学习这种从经验学习的软件技术重现光明。在计算机诞生的早期，机器学习的概念已经出现，各种理论天马行空，限于计算成本而未能普及。随着计算设备的普及，日常生活中越来越多的机器学习应用，可以说它的成功开始变得习以为常。新应用如雨后春笋一般出现，很多都从机器学习中获得动力。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/0-perface.html"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>ipython</category><category>Machine Learning</category><category>Python</category><guid>http://muxuezi.github.io/posts/0-perface.html</guid><pubDate>Thu, 09 Jul 2015 07:20:14 GMT</pubDate></item><item><title>10-from-the-perceptron-to-artificial-neural-networks</title><link>http://muxuezi.github.io/posts/10-from-the-perceptron-to-artificial-neural-networks.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="从感知器到人工神经网络"&gt;从感知器到人工神经网络&lt;a class="anchor-link" href="http://muxuezi.github.io/posts/10-from-the-perceptron-to-artificial-neural-networks.html#%E4%BB%8E%E6%84%9F%E7%9F%A5%E5%99%A8%E5%88%B0%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在&lt;em&gt;第8章，感知器&lt;/em&gt;里，我们介绍了感知器，一种线性模型用来做二元分类。感知器不是一个通用函数近似器；它的决策边界必须是一个超平面。上一章里面介绍的支持向量机，用核函数修正了感知器的不足，将特征向量有效的映射到更高维的空间使得样本成为线性可分的数据集。本章，我们将介绍人工神经网络（artificial neural networks，ANN），一种用于强大的非线性回归和分类模型，用新的策略来克服感知器的缺点。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/10-from-the-perceptron-to-artificial-neural-networks.html"&gt;Read more…&lt;/a&gt; (9 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>ipython</category><category>Machine Learning</category><category>Python</category><guid>http://muxuezi.github.io/posts/10-from-the-perceptron-to-artificial-neural-networks.html</guid><pubDate>Thu, 09 Jul 2015 07:19:44 GMT</pubDate></item><item><title>9-from-the-perceptron-to-support-vector-machines</title><link>http://muxuezi.github.io/posts/9-from-the-perceptron-to-support-vector-machines.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="从感知器到支持向量机"&gt;从感知器到支持向量机&lt;a class="anchor-link" href="http://muxuezi.github.io/posts/9-from-the-perceptron-to-support-vector-machines.html#%E4%BB%8E%E6%84%9F%E7%9F%A5%E5%99%A8%E5%88%B0%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上一章我们介绍了感知器。作为一种二元分类器，感知器不能有效的解决线性不可分问题。其实在&lt;em&gt;第二章，线性回归&lt;/em&gt;里面已经遇到过类似的问题，当时需要解决一个解释变量与响应变量存在非线性关系的问题。为了提高模型的准确率，我们引入了一种特殊的多元线性回归模型，多项式回归。通过对特征进行合理的组合，我们建立了高维特征空间的解释变量与响应变量的线性关系模型。&lt;/p&gt;
&lt;p&gt;随着特征空间的维度的不断增多，在用线性模型近似非线性函数时，上述方法似乎依然可行，但是有两个问题不可避免。首先是计算问题，计算映射的特征，操纵高维的向量需要更强大的计算能力。然后是与算法归纳有关的问题，特征空间的维度的不断增多会导致维度灾难。从高维的特征变量中学习，要避免拟合过度，就需要呈指数级增长的训练数据。&lt;/p&gt;
&lt;p&gt;这一章，我们将介绍一种强大的分类和回归模型，称为支持向量机（support vector machine，SVM）。首先，我们将学习高维空间的特征映射。然后，我们将介绍，在处理被映射到高维空间的数据时，支持向量机是如何缓解那些计算与综合问题的。有许多书整本整本的介绍SVM，相关的优化算法需要比前面章节里介绍其他算法更多的数学知识。我们不再用前面那些章节的小例子来演示算法，而是通过直观的案例来介绍scikit-learn如何有效的使用SVM去解决问题。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/9-from-the-perceptron-to-support-vector-machines.html"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>ipython</category><category>Machine Learning</category><category>Python</category><guid>http://muxuezi.github.io/posts/9-from-the-perceptron-to-support-vector-machines.html</guid><pubDate>Wed, 08 Jul 2015 01:15:04 GMT</pubDate></item><item><title>8-the-perceptron</title><link>http://muxuezi.github.io/posts/8-the-perceptron.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="感知器"&gt;感知器&lt;a class="anchor-link" href="http://muxuezi.github.io/posts/8-the-perceptron.html#%E6%84%9F%E7%9F%A5%E5%99%A8"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;前面，我们介绍了广义线性模型，用联接方程描述解释变量、超参数和响应变量的线性关系。这一章，我们将介绍另一种线性模型，称为感知器（perceptron）。感知器是一种研究单个训练样本的二元分类器，训练较大的数据集很有用。而且，感知器和它的不足激发了我们后面两种将介绍的模型。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/8-the-perceptron.html"&gt;Read more…&lt;/a&gt; (5 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>ipython</category><category>Machine Learning</category><category>Python</category><guid>http://muxuezi.github.io/posts/8-the-perceptron.html</guid><pubDate>Wed, 08 Jul 2015 01:13:39 GMT</pubDate></item><item><title>7-dimensionality-reduction-with-pca</title><link>http://muxuezi.github.io/posts/7-dimensionality-reduction-with-pca.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="用PCA降维"&gt;用PCA降维&lt;a class="anchor-link" href="http://muxuezi.github.io/posts/7-dimensionality-reduction-with-pca.html#%E7%94%A8PCA%E9%99%8D%E7%BB%B4"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;本章我们将介绍一种降维方法，PCA（Principal Component Analysis，主成分分析）。降维致力于解决三类问题。第一，降维可以缓解维度灾难问题。第二，降维可以在压缩数据的同时让信息损失最小化。第三，理解几百个维度的数据结构很困难，两三个维度的数据通过可视化更容易理解。下面，我们用PCA将一个高维数据降成二维，方便可视化，之后，我们建一个脸部识别系统。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/7-dimensionality-reduction-with-pca.html"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>ipython</category><category>Machine Learning</category><category>Python</category><guid>http://muxuezi.github.io/posts/7-dimensionality-reduction-with-pca.html</guid><pubDate>Thu, 02 Jul 2015 01:38:42 GMT</pubDate></item><item><title>4-from-linear-regression-to-logistic-regression</title><link>http://muxuezi.github.io/posts/4-from-linear-regression-to-logistic-regression.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="从线性回归到逻辑回归"&gt;从线性回归到逻辑回归&lt;a class="anchor-link" href="http://muxuezi.github.io/posts/4-from-linear-regression-to-logistic-regression.html#%E4%BB%8E%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%88%B0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在第2章，线性回归里面，我们介绍了一元线性回归，多元线性回归和多项式回归。这些模型都是广义线性回归模型的具体形式，广义线性回归是一种灵活的框架，比普通线性回归要求更少的假设。这一章，我们讨论广义线性回归模型的具体形式的另一种形式，逻辑回归（logistic regression）。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/4-from-linear-regression-to-logistic-regression.html"&gt;Read more…&lt;/a&gt; (9 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>ipython</category><category>Machine Learning</category><category>Python</category><guid>http://muxuezi.github.io/posts/4-from-linear-regression-to-logistic-regression.html</guid><pubDate>Mon, 29 Jun 2015 12:49:07 GMT</pubDate></item><item><title>6-clustering-with-k-means</title><link>http://muxuezi.github.io/posts/6-clustering-with-k-means.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="K-Means聚类"&gt;K-Means聚类&lt;a class="anchor-link" href="http://muxuezi.github.io/posts/6-clustering-with-k-means.html#K-Means%E8%81%9A%E7%B1%BB"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;前面几章我们介绍了监督学习，包括从带标签的数据中学习的回归和分类算法。本章，我们讨论无监督学习算法，聚类（clustering）。聚类是用于找出不带标签数据的相似性的算法。我们将介绍K-Means聚类思想，解决一个图像压缩问题，然后对算法的效果进行评估。最后，我们把聚类和分类算法组合起来，解决一个半监督学习问题。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/6-clustering-with-k-means.html"&gt;Read more…&lt;/a&gt; (10 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>ipython</category><category>Machine Learning</category><category>Python</category><guid>http://muxuezi.github.io/posts/6-clustering-with-k-means.html</guid><pubDate>Mon, 29 Jun 2015 12:29:49 GMT</pubDate></item><item><title>5-nonlinear-classification-and-regression-with-decision-trees</title><link>http://muxuezi.github.io/posts/5-nonlinear-classification-and-regression-with-decision-trees.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="决策树——非线性回归与分类"&gt;决策树——非线性回归与分类&lt;a class="anchor-link" href="http://muxuezi.github.io/posts/5-nonlinear-classification-and-regression-with-decision-trees.html#%E5%86%B3%E7%AD%96%E6%A0%91%E2%80%94%E2%80%94%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%8E%E5%88%86%E7%B1%BB"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;前面几章，我们介绍的模型都是广义线性模型，基本方法都是通过联接方程构建解释变量与若干响应变量的关联关系。我们用多元线性回归解决回归问题，逻辑回归解决分类问题。本章我们要讨论一种简单的非线性模型，用来解决回归与分类问题，称为决策树（decision tree）。首先，我们将用决策树做一个广告屏蔽器，可以将网页中的广告内容屏蔽掉。之后，我们介绍集成学习（lensemble learning）方法，通过将一系列学习方法集成使用，以取得更好的训练效果。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/5-nonlinear-classification-and-regression-with-decision-trees.html"&gt;Read more…&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>ipython</category><category>Machine Learning</category><category>Python</category><guid>http://muxuezi.github.io/posts/5-nonlinear-classification-and-regression-with-decision-trees.html</guid><pubDate>Mon, 29 Jun 2015 12:29:22 GMT</pubDate></item><item><title>1-the-fundamentals-of-machine-learning</title><link>http://muxuezi.github.io/posts/1-the-fundamentals-of-machine-learning.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="机器学习基础"&gt;机器学习基础&lt;a class="anchor-link" href="http://muxuezi.github.io/posts/1-the-fundamentals-of-machine-learning.html#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;本章我们简要介绍下机器学习（Machine Learning）的基本概念。主要介绍机器学习算法的应用，监督学习和无监督学习（supervised-unsupervised learning）的应用场景，训练和测试数据的用法，学习效果评估方式。最后，我们介绍scikit-learn及其安装方法。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/1-the-fundamentals-of-machine-learning.html"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>ipython</category><category>Machine Learning</category><category>Python</category><guid>http://muxuezi.github.io/posts/1-the-fundamentals-of-machine-learning.html</guid><pubDate>Wed, 24 Jun 2015 05:45:05 GMT</pubDate></item><item><title>kivy-ch1-clock-app</title><link>http://muxuezi.github.io/posts/kivy-ch1-clock-app.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="时钟app"&gt;时钟app&lt;a class="anchor-link" href="http://muxuezi.github.io/posts/kivy-ch1-clock-app.html#%E6%97%B6%E9%92%9Fapp"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一个仿iOS和Android内置时钟应用的app。分两部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;个没有交互的数字时钟，简述Kivy的事件驱动(event-driven)方法，引入计时器的功能，持续更新。&lt;/li&gt;
&lt;li&gt;交互的秒表功能，设计流畅的自适应布局。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/kivy-ch1-clock-app.html"&gt;Read more…&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>ipython</category><category>Kivy</category><category>Python</category><guid>http://muxuezi.github.io/posts/kivy-ch1-clock-app.html</guid><pubDate>Wed, 24 Jun 2015 05:45:00 GMT</pubDate></item></channel></rss>