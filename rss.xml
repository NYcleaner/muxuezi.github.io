<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>绿萝间</title><link>http://muxuezi.github.io/</link><description>Tao Junjie blog</description><language>en</language><lastBuildDate>Fri, 31 Jul 2015 08:10:16 GMT</lastBuildDate><generator>http://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>双色球2015088期(2015-07-30)数据分析报告</title><link>http://muxuezi.github.io/posts/slott-2015088-2015-07-30-report.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;p&gt;如有雷同，纯属巧合&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/slott-2015088-2015-07-30-report.html"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>Lottery</category><guid>http://muxuezi.github.io/posts/slott-2015088-2015-07-30-report.html</guid><pubDate>Fri, 31 Jul 2015 00:00:00 GMT</pubDate></item><item><title>大乐透15087期(2015-07-29)数据分析报告</title><link>http://muxuezi.github.io/posts/dlott-15087-2015-07-29-report.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;p&gt;如有雷同，纯属巧合&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/dlott-15087-2015-07-29-report.html"&gt;Read more…&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>Lottery</category><guid>http://muxuezi.github.io/posts/dlott-15087-2015-07-29-report.html</guid><pubDate>Thu, 30 Jul 2015 00:00:00 GMT</pubDate></item><item><title>双色球2015087期(2015-07-28)数据分析报告</title><link>http://muxuezi.github.io/posts/slott-2015087-2015-07-28-report.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;p&gt;如有雷同，纯属巧合&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/slott-2015087-2015-07-28-report.html"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>Lottery</category><guid>http://muxuezi.github.io/posts/slott-2015087-2015-07-28-report.html</guid><pubDate>Wed, 29 Jul 2015 00:00:00 GMT</pubDate></item><item><title>大乐透15086期(2015-07-27)数据分析报告</title><link>http://muxuezi.github.io/posts/dlott-15086-2015-07-27-report.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;p&gt;如有雷同，纯属巧合&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/dlott-15086-2015-07-27-report.html"&gt;Read more…&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>Lottery</category><guid>http://muxuezi.github.io/posts/dlott-15086-2015-07-27-report.html</guid><pubDate>Tue, 28 Jul 2015 00:00:00 GMT</pubDate></item><item><title>working-with-categorical-variables</title><link>http://muxuezi.github.io/posts/working-with-categorical-variables.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="分类变量处理"&gt;分类变量处理&lt;a class="anchor-link" href="http://muxuezi.github.io/posts/working-with-categorical-variables.html#%E5%88%86%E7%B1%BB%E5%8F%98%E9%87%8F%E5%A4%84%E7%90%86"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;分类变量是经常遇到的问题。一方面它们提供了信息；另一方面，它们可能是文本形式——纯文字或者与文字相关的整数——就像表格的索引一样。&lt;/p&gt;
&lt;p&gt;因此，我们在建模的时候往往需要将这些变量量化，但是仅仅用简单的&lt;code&gt;id&lt;/code&gt;或者原来的形式是不行的。因为我们也需要避免在上一节里&lt;em&gt;通过阈值创建二元特征&lt;/em&gt;遇到的问题。如果我们把数据看成是连续的，那么也必须解释成连续的。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/working-with-categorical-variables.html"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>Machine Learning</category><category>Python</category><category>ipython</category><category>scikit-learn cookbook</category><guid>http://muxuezi.github.io/posts/working-with-categorical-variables.html</guid><pubDate>Mon, 27 Jul 2015 06:59:14 GMT</pubDate></item><item><title>using-truncated-svd-to-reduce-dimensionality</title><link>http://muxuezi.github.io/posts/using-truncated-svd-to-reduce-dimensionality.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="用截断奇异值分解降维"&gt;用截断奇异值分解降维&lt;a class="anchor-link" href="http://muxuezi.github.io/posts/using-truncated-svd-to-reduce-dimensionality.html#%E7%94%A8%E6%88%AA%E6%96%AD%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3%E9%99%8D%E7%BB%B4"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;截断奇异值分解（Truncated singular value decomposition，TSVD）是一种矩阵因式分解（factorization）技术，将矩阵$M$分解成$U$，$\Sigma$和$V$。它与PCA很像，只是SVD分解是在数据矩阵上进行，而PCA是在数据的协方差矩阵上进行。通常，SVD用于发现矩阵的主成份。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/using-truncated-svd-to-reduce-dimensionality.html"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>Machine Learning</category><category>Python</category><category>ipython</category><category>scikit-learn cookbook</category><guid>http://muxuezi.github.io/posts/using-truncated-svd-to-reduce-dimensionality.html</guid><pubDate>Mon, 27 Jul 2015 06:59:09 GMT</pubDate></item><item><title>using-stochastic-gradient-descent-for-regression</title><link>http://muxuezi.github.io/posts/using-stochastic-gradient-descent-for-regression.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="用随机梯度下降处理回归"&gt;用随机梯度下降处理回归&lt;a class="anchor-link" href="http://muxuezi.github.io/posts/using-stochastic-gradient-descent-for-regression.html#%E7%94%A8%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%A4%84%E7%90%86%E5%9B%9E%E5%BD%92"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;本主题将介绍随机梯度下降法（Stochastic Gradient Descent，SGD），我们将用它解决回归问题，后面我们还用它处理分类问题。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/using-stochastic-gradient-descent-for-regression.html"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>Machine Learning</category><category>Python</category><category>ipython</category><category>scikit-learn cookbook</category><guid>http://muxuezi.github.io/posts/using-stochastic-gradient-descent-for-regression.html</guid><pubDate>Mon, 27 Jul 2015 06:59:03 GMT</pubDate></item><item><title>using-pipelines-for-multiple-preprocessing-steps</title><link>http://muxuezi.github.io/posts/using-pipelines-for-multiple-preprocessing-steps.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="用管线命令处理多个步骤"&gt;用管线命令处理多个步骤&lt;a class="anchor-link" href="http://muxuezi.github.io/posts/using-pipelines-for-multiple-preprocessing-steps.html#%E7%94%A8%E7%AE%A1%E7%BA%BF%E5%91%BD%E4%BB%A4%E5%A4%84%E7%90%86%E5%A4%9A%E4%B8%AA%E6%AD%A5%E9%AA%A4"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;管线命令不经常用，但是很有用。它们可以把多个步骤组合成一个对象执行。这样可以更方便灵活地调节和控制整个模型的配置，而不只是一个一个步骤调节。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/using-pipelines-for-multiple-preprocessing-steps.html"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>Machine Learning</category><category>Python</category><category>ipython</category><category>scikit-learn cookbook</category><guid>http://muxuezi.github.io/posts/using-pipelines-for-multiple-preprocessing-steps.html</guid><pubDate>Mon, 27 Jul 2015 06:58:57 GMT</pubDate></item><item><title>using-gaussian-processes-for-regression</title><link>http://muxuezi.github.io/posts/using-gaussian-processes-for-regression.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="用正态随机过程处理回归"&gt;用正态随机过程处理回归&lt;a class="anchor-link" href="http://muxuezi.github.io/posts/using-gaussian-processes-for-regression.html#%E7%94%A8%E6%AD%A3%E6%80%81%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E5%A4%84%E7%90%86%E5%9B%9E%E5%BD%92"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;这个主题将介绍如何用正态随机过程（Gaussian process，GP）处理回归问题。在线性模型部分，我们曾经见过在变量间可能存在相关性时，如何用贝叶斯岭回归(Bayesian Ridge Regression)表示先验概率分布（prior）信息。&lt;/p&gt;
&lt;p&gt;正态分布过程关心的是方程而不是均值。但是，如果我们假设一个正态分布的均值为0，那么我们需要确定协方差。&lt;/p&gt;
&lt;p&gt;这样处理就与线性回归问题中先验概率分布可以用相关系数表示的情况类似。用GP处理的先验就可以用数据、样本数据间协方差构成函数表示，因此必须从数据中拟合得出。具体内容参考&lt;a href="http://www.gaussianprocess.org/"&gt;The Gaussian Processes Web Site&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/using-gaussian-processes-for-regression.html"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>Machine Learning</category><category>Python</category><category>ipython</category><category>scikit-learn cookbook</category><guid>http://muxuezi.github.io/posts/using-gaussian-processes-for-regression.html</guid><pubDate>Mon, 27 Jul 2015 06:58:51 GMT</pubDate></item><item><title>using-factor-analytics-for-decomposition</title><link>http://muxuezi.github.io/posts/using-factor-analytics-for-decomposition.html</link><dc:creator>tj2</dc:creator><description>&lt;div&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="用因子分析降维"&gt;用因子分析降维&lt;a class="anchor-link" href="http://muxuezi.github.io/posts/using-factor-analytics-for-decomposition.html#%E7%94%A8%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90%E9%99%8D%E7%BB%B4"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因子分析（factor analysis）是另一种降维方法。与PCA不同的是，因子分析有假设而PCA没有假设。因子分析的基本假设是有一些隐藏特征与数据集的特征相关。&lt;/p&gt;
&lt;p&gt;这个主题将浓缩（boil down）样本数据集的显性特征，尝试像理解因变量一样地理解自变量之间的隐藏特征。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://muxuezi.github.io/posts/using-factor-analytics-for-decomposition.html"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>CHS</category><category>Machine Learning</category><category>Python</category><category>ipython</category><category>scikit-learn cookbook</category><guid>http://muxuezi.github.io/posts/using-factor-analytics-for-decomposition.html</guid><pubDate>Mon, 27 Jul 2015 06:58:45 GMT</pubDate></item></channel></rss>